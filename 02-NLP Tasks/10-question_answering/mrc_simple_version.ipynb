{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于截断策略的机器阅读理解任务实现"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1 导入相关包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HTTPs_proxy'] = 'http://127.0.0.1:7890'\n",
    "os.environ['HTTP_PROXY'] = 'http://127.0.0.1:7890'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "For effortless bug reporting copy-paste your error into this form: https://docs.google.com/forms/d/e/1FAIpQLScPB8emS3Thkp66nvqwmjTEgxp8Y9ufuWTzFyr9kJ5AoI47dQ/viewform?usp=sf_link\n",
      "================================================================================\n",
      "CUDA SETUP: Loading binary d:\\anaconda\\envs\\roboflow\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda116.dll...\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer, DefaultDataCollator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2 数据集加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'context', 'question', 'answers'],\n",
       "        num_rows: 10142\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'context', 'question', 'answers'],\n",
       "        num_rows: 3219\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'context', 'question', 'answers'],\n",
       "        num_rows: 1002\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果可以联网，直接使用load_dataset进行加载\n",
    "#datasets = load_dataset(\"cmrc2018\", cache_dir=\"data\")\n",
    "# 如果无法联网，则使用下面的方式加载数据集\n",
    "datasets = DatasetDict.load_from_disk(\"mrc_data\")\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'TRAIN_186_QUERY_0',\n",
       " 'context': '范廷颂枢机（，），圣名保禄·若瑟（），是越南罗马天主教枢机。1963年被任为主教；1990年被擢升为天主教河内总教区宗座署理；1994年被擢升为总主教，同年年底被擢升为枢机；2009年2月离世。范廷颂于1919年6月15日在越南宁平省天主教发艳教区出生；童年时接受良好教育后，被一位越南神父带到河内继续其学业。范廷颂于1940年在河内大修道院完成神学学业。范廷颂于1949年6月6日在河内的主教座堂晋铎；及后被派到圣女小德兰孤儿院服务。1950年代，范廷颂在河内堂区创建移民接待中心以收容到河内避战的难民。1954年，法越战争结束，越南民主共和国建都河内，当时很多天主教神职人员逃至越南的南方，但范廷颂仍然留在河内。翌年管理圣若望小修院；惟在1960年因捍卫修院的自由、自治及拒绝政府在修院设政治课的要求而被捕。1963年4月5日，教宗任命范廷颂为天主教北宁教区主教，同年8月15日就任；其牧铭为「我信天主的爱」。由于范廷颂被越南政府软禁差不多30年，因此他无法到所属堂区进行牧灵工作而专注研读等工作。范廷颂除了面对战争、贫困、被当局迫害天主教会等问题外，也秘密恢复修院、创建女修会团体等。1990年，教宗若望保禄二世在同年6月18日擢升范廷颂为天主教河内总教区宗座署理以填补该教区总主教的空缺。1994年3月23日，范廷颂被教宗若望保禄二世擢升为天主教河内总教区总主教并兼天主教谅山教区宗座署理；同年11月26日，若望保禄二世擢升范廷颂为枢机。范廷颂在1995年至2001年期间出任天主教越南主教团主席。2003年4月26日，教宗若望保禄二世任命天主教谅山教区兼天主教高平教区吴光杰主教为天主教河内总教区署理主教；及至2005年2月19日，范廷颂因获批辞去总主教职务而荣休；吴光杰同日真除天主教河内总教区总主教职务。范廷颂于2009年2月22日清晨在河内离世，享年89岁；其葬礼于同月26日上午在天主教河内总教区总主教座堂举行。',\n",
       " 'question': '范廷颂是什么时候被任为主教的？',\n",
       " 'answers': {'text': ['1963年'], 'answer_start': [30]}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2453a421e0ca458db034dd7184926738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/19.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\roboflow\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sjf19\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8410513b9eb473abfe3d93e5c45d0ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/659 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2ac847e4914d2db3591f69cf56de81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/110k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feabaf8c0d8f4bd3a5b2e1b66ff43d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/269k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "757a15df28f34f5e81d0df4db4e5b3e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)in/added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4bd530582754750ad16daa761de5a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='hfl/chinese-macbert-base', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"hfl/chinese-macbert-base\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataset = datasets[\"train\"].select(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'TRAIN_186_QUERY_1',\n",
       " 'context': '范廷颂枢机（，），圣名保禄·若瑟（），是越南罗马天主教枢机。1963年被任为主教；1990年被擢升为天主教河内总教区宗座署理；1994年被擢升为总主教，同年年底被擢升为枢机；2009年2月离世。范廷颂于1919年6月15日在越南宁平省天主教发艳教区出生；童年时接受良好教育后，被一位越南神父带到河内继续其学业。范廷颂于1940年在河内大修道院完成神学学业。范廷颂于1949年6月6日在河内的主教座堂晋铎；及后被派到圣女小德兰孤儿院服务。1950年代，范廷颂在河内堂区创建移民接待中心以收容到河内避战的难民。1954年，法越战争结束，越南民主共和国建都河内，当时很多天主教神职人员逃至越南的南方，但范廷颂仍然留在河内。翌年管理圣若望小修院；惟在1960年因捍卫修院的自由、自治及拒绝政府在修院设政治课的要求而被捕。1963年4月5日，教宗任命范廷颂为天主教北宁教区主教，同年8月15日就任；其牧铭为「我信天主的爱」。由于范廷颂被越南政府软禁差不多30年，因此他无法到所属堂区进行牧灵工作而专注研读等工作。范廷颂除了面对战争、贫困、被当局迫害天主教会等问题外，也秘密恢复修院、创建女修会团体等。1990年，教宗若望保禄二世在同年6月18日擢升范廷颂为天主教河内总教区宗座署理以填补该教区总主教的空缺。1994年3月23日，范廷颂被教宗若望保禄二世擢升为天主教河内总教区总主教并兼天主教谅山教区宗座署理；同年11月26日，若望保禄二世擢升范廷颂为枢机。范廷颂在1995年至2001年期间出任天主教越南主教团主席。2003年4月26日，教宗若望保禄二世任命天主教谅山教区兼天主教高平教区吴光杰主教为天主教河内总教区署理主教；及至2005年2月19日，范廷颂因获批辞去总主教职务而荣休；吴光杰同日真除天主教河内总教区总主教职务。范廷颂于2009年2月22日清晨在河内离世，享年89岁；其葬礼于同月26日上午在天主教河内总教区总主教座堂举行。',\n",
       " 'question': '1990年，范廷颂担任什么职务？',\n",
       " 'answers': {'text': ['1990年被擢升为天主教河内总教区宗座署理'], 'answer_start': [41]}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_examp = tokenizer(text=sample_dataset[\"question\"], text_pair=sample_dataset[\"context\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_examp.keys() # 三个基本的key：input_ids, token_type_ids, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 5745, 2455, 7563, 3221, 784, 720, 3198, 952, 6158, 818, 711, 712, 3136, 4638, 8043, 102, 5745, 2455, 7563, 3364, 3322, 8020, 8024, 8021, 8024, 1760, 1399, 924, 4882, 185, 5735, 4449, 8020, 8021, 8024, 3221, 6632, 1298, 5384, 7716, 1921, 712, 3136, 3364, 3322, 511, 9155, 2399, 6158, 818, 711, 712, 3136, 8039, 8431, 2399, 6158, 3091, 1285, 711, 1921, 712, 3136, 3777, 1079, 2600, 3136, 1277, 2134, 2429, 5392, 4415, 8039, 8447, 2399, 6158, 3091, 1285, 711, 2600, 712, 3136, 8024, 1398, 2399, 2399, 2419, 6158, 3091, 1285, 711, 3364, 3322, 8039, 8170, 2399, 123, 3299, 4895, 686, 511, 5745, 2455, 7563, 754, 9915, 2399, 127, 3299, 8115, 3189, 1762, 6632, 1298, 2123, 2398, 4689, 1921, 712, 3136, 1355, 5683, 3136, 1277, 1139, 4495, 8039, 4997, 2399, 3198, 2970, 1358, 5679, 1962, 3136, 5509, 1400, 8024, 6158, 671, 855, 6632, 1298, 4868, 4266, 2372, 1168, 3777, 1079, 5326, 5330, 1071, 2110, 689, 511, 5745, 2455, 7563, 754, 9211, 2399, 1762, 3777, 1079, 1920, 934, 6887, 7368, 2130, 2768, 4868, 2110, 2110, 689, 511, 5745, 2455, 7563, 754, 8594, 2399, 127, 3299, 127, 3189, 1762, 3777, 1079, 4638, 712, 3136, 2429, 1828, 3232, 7195, 8039, 1350, 1400, 6158, 3836, 1168, 1760, 1957, 2207, 2548, 1065, 2109, 1036, 7368, 3302, 1218, 511, 8707, 2399, 807, 8024, 5745, 2455, 7563, 1762, 3777, 1079, 1828, 1277, 1158, 2456, 4919, 3696, 2970, 2521, 704, 2552, 809, 3119, 2159, 1168, 3777, 1079, 6912, 2773, 4638, 7410, 3696, 511, 9258, 2399, 8024, 3791, 6632, 2773, 751, 5310, 3338, 8024, 6632, 1298, 3696, 712, 1066, 1469, 1744, 2456, 6963, 3777, 1079, 8024, 2496, 3198, 2523, 1914, 1921, 712, 3136, 4868, 5466, 782, 1447, 6845, 5635, 6632, 1298, 4638, 1298, 3175, 8024, 852, 5745, 2455, 7563, 793, 4197, 4522, 1762, 3777, 1079, 511, 5422, 2399, 5052, 4415, 1760, 5735, 3307, 2207, 934, 7368, 8039, 2668, 1762, 8779, 2399, 1728, 2932, 1310, 934, 7368, 4638, 5632, 4507, 510, 5632, 3780, 1350, 2867, 5318, 3124, 2424, 1762, 934, 7368, 6392, 3124, 3780, 6440, 4638, 6206, 3724, 5445, 6158, 2936, 511, 9155, 2399, 125, 3299, 126, 3189, 8024, 3136, 2134, 818, 1462, 5745, 2455, 7563, 711, 1921, 712, 3136, 1266, 2123, 3136, 1277, 712, 3136, 8024, 1398, 2399, 129, 3299, 8115, 3189, 2218, 818, 8039, 1071, 4288, 7208, 711, 519, 2769, 928, 1921, 712, 4638, 4263, 520, 511, 4507, 754, 5745, 2455, 7563, 6158, 6632, 1298, 3124, 2424, 6763, 4881, 2345, 679, 1914, 8114, 2399, 8024, 1728, 3634, 800, 3187, 3791, 1168, 2792, 2247, 1828, 1277, 6822, 6121, 4288, 4130, 2339, 868, 5445, 683, 3800, 4777, 6438, 5023, 2339, 868, 511, 5745, 2455, 7563, 7370, 749, 7481, 2190, 2773, 751, 510, 6577, 1737, 510, 6158, 2496, 2229, 6833, 2154, 1921, 712, 3136, 833, 5023, 7309, 7579, 1912, 8024, 738, 4908, 2166, 2612, 1908, 934, 7368, 510, 1158, 2456, 1957, 934, 833, 1730, 860, 5023, 511, 8431, 2399, 8024, 3136, 2134, 5735, 3307, 924, 4882, 753, 686, 1762, 1398, 2399, 127, 3299, 8123, 3189, 3091, 1285, 5745, 2455, 7563, 711, 1921, 712, 3136, 3777, 1079, 2600, 3136, 1277, 2134, 2429, 5392, 4415, 809, 1856, 6133, 6421, 3136, 1277, 2600, 712, 3136, 4638, 4958, 5375, 511, 8447, 2399, 124, 3299, 8133, 3189, 8024, 5745, 2455, 7563, 6158, 3136, 2134, 5735, 3307, 924, 4882, 753, 686, 3091, 1285, 711, 1921, 712, 3136, 3777, 1079, 2600, 3136, 1277, 2600, 712, 3136, 2400, 1076, 1921, 712, 3136, 6446, 2255, 3136, 1277, 2134, 2429, 5392, 4415, 8039, 1398, 2399, 8111, 3299, 8153, 3189, 8024, 5735, 3307, 924, 4882, 753, 686, 3091, 1285, 5745, 2455, 7563, 711, 3364, 3322, 511, 5745, 2455, 7563, 1762, 8396, 2399, 5635, 8285, 2399, 3309, 7313, 1139, 818, 1921, 712, 3136, 6632, 1298, 712, 3136, 1730, 712, 2375, 511, 8263, 2399, 125, 3299, 8153, 3189, 8024, 3136, 2134, 5735, 3307, 924, 4882, 753, 686, 818, 1462, 1921, 712, 3136, 6446, 2255, 3136, 1277, 1076, 1921, 712, 3136, 7770, 2398, 3136, 1277, 1426, 1045, 3345, 712, 3136, 711, 1921, 712, 3136, 3777, 1079, 2600, 3136, 1277, 5392, 4415, 712, 3136, 8039, 1350, 5635, 8232, 2399, 123, 3299, 8131, 3189, 8024, 5745, 2455, 7563, 1728, 5815, 2821, 6791, 1343, 2600, 712, 3136, 5466, 1218, 5445, 5783, 828, 8039, 1426, 1045, 3345, 1398, 3189, 4696, 7370, 1921, 712, 3136, 3777, 1079, 2600, 3136, 1277, 2600, 712, 3136, 5466, 1218, 511, 5745, 2455, 7563, 754, 8170, 2399, 123, 3299, 8130, 3189, 3926, 3247, 1762, 3777, 1079, 4895, 686, 8024, 775, 2399, 8426, 2259, 8039, 1071, 5873, 4851, 754, 1398, 3299, 8153, 3189, 677, 1286, 1762, 1921, 712, 3136, 3777, 1079, 2600, 3136, 1277, 2600, 712, 3136, 2429, 1828, 715, 6121, 511, 102]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_examp['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(101, 0), (5745, 0), (2455, 0), (7563, 0), (3221, 0), (784, 0), (720, 0), (3198, 0), (952, 0), (6158, 0), (818, 0), (711, 0), (712, 0), (3136, 0), (4638, 0), (8043, 0), (102, 0), (5745, 1), (2455, 1), (7563, 1), (3364, 1), (3322, 1), (8020, 1), (8024, 1), (8021, 1), (8024, 1), (1760, 1), (1399, 1), (924, 1), (4882, 1), (185, 1), (5735, 1), (4449, 1), (8020, 1), (8021, 1), (8024, 1), (3221, 1), (6632, 1), (1298, 1), (5384, 1), (7716, 1), (1921, 1), (712, 1), (3136, 1), (3364, 1), (3322, 1), (511, 1), (9155, 1), (2399, 1), (6158, 1), (818, 1), (711, 1), (712, 1), (3136, 1), (8039, 1), (8431, 1), (2399, 1), (6158, 1), (3091, 1), (1285, 1), (711, 1), (1921, 1), (712, 1), (3136, 1), (3777, 1), (1079, 1), (2600, 1), (3136, 1), (1277, 1), (2134, 1), (2429, 1), (5392, 1), (4415, 1), (8039, 1), (8447, 1), (2399, 1), (6158, 1), (3091, 1), (1285, 1), (711, 1), (2600, 1), (712, 1), (3136, 1), (8024, 1), (1398, 1), (2399, 1), (2399, 1), (2419, 1), (6158, 1), (3091, 1), (1285, 1), (711, 1), (3364, 1), (3322, 1), (8039, 1), (8170, 1), (2399, 1), (123, 1), (3299, 1), (4895, 1), (686, 1), (511, 1), (5745, 1), (2455, 1), (7563, 1), (754, 1), (9915, 1), (2399, 1), (127, 1), (3299, 1), (8115, 1), (3189, 1), (1762, 1), (6632, 1), (1298, 1), (2123, 1), (2398, 1), (4689, 1), (1921, 1), (712, 1), (3136, 1), (1355, 1), (5683, 1), (3136, 1), (1277, 1), (1139, 1), (4495, 1), (8039, 1), (4997, 1), (2399, 1), (3198, 1), (2970, 1), (1358, 1), (5679, 1), (1962, 1), (3136, 1), (5509, 1), (1400, 1), (8024, 1), (6158, 1), (671, 1), (855, 1), (6632, 1), (1298, 1), (4868, 1), (4266, 1), (2372, 1), (1168, 1), (3777, 1), (1079, 1), (5326, 1), (5330, 1), (1071, 1), (2110, 1), (689, 1), (511, 1), (5745, 1), (2455, 1), (7563, 1), (754, 1), (9211, 1), (2399, 1), (1762, 1), (3777, 1), (1079, 1), (1920, 1), (934, 1), (6887, 1), (7368, 1), (2130, 1), (2768, 1), (4868, 1), (2110, 1), (2110, 1), (689, 1), (511, 1), (5745, 1), (2455, 1), (7563, 1), (754, 1), (8594, 1), (2399, 1), (127, 1), (3299, 1), (127, 1), (3189, 1), (1762, 1), (3777, 1), (1079, 1), (4638, 1), (712, 1), (3136, 1), (2429, 1), (1828, 1), (3232, 1), (7195, 1), (8039, 1), (1350, 1), (1400, 1), (6158, 1), (3836, 1), (1168, 1), (1760, 1), (1957, 1), (2207, 1), (2548, 1), (1065, 1), (2109, 1), (1036, 1), (7368, 1), (3302, 1), (1218, 1), (511, 1), (8707, 1), (2399, 1), (807, 1), (8024, 1), (5745, 1), (2455, 1), (7563, 1), (1762, 1), (3777, 1), (1079, 1), (1828, 1), (1277, 1), (1158, 1), (2456, 1), (4919, 1), (3696, 1), (2970, 1), (2521, 1), (704, 1), (2552, 1), (809, 1), (3119, 1), (2159, 1), (1168, 1), (3777, 1), (1079, 1), (6912, 1), (2773, 1), (4638, 1), (7410, 1), (3696, 1), (511, 1), (9258, 1), (2399, 1), (8024, 1), (3791, 1), (6632, 1), (2773, 1), (751, 1), (5310, 1), (3338, 1), (8024, 1), (6632, 1), (1298, 1), (3696, 1), (712, 1), (1066, 1), (1469, 1), (1744, 1), (2456, 1), (6963, 1), (3777, 1), (1079, 1), (8024, 1), (2496, 1), (3198, 1), (2523, 1), (1914, 1), (1921, 1), (712, 1), (3136, 1), (4868, 1), (5466, 1), (782, 1), (1447, 1), (6845, 1), (5635, 1), (6632, 1), (1298, 1), (4638, 1), (1298, 1), (3175, 1), (8024, 1), (852, 1), (5745, 1), (2455, 1), (7563, 1), (793, 1), (4197, 1), (4522, 1), (1762, 1), (3777, 1), (1079, 1), (511, 1), (5422, 1), (2399, 1), (5052, 1), (4415, 1), (1760, 1), (5735, 1), (3307, 1), (2207, 1), (934, 1), (7368, 1), (8039, 1), (2668, 1), (1762, 1), (8779, 1), (2399, 1), (1728, 1), (2932, 1), (1310, 1), (934, 1), (7368, 1), (4638, 1), (5632, 1), (4507, 1), (510, 1), (5632, 1), (3780, 1), (1350, 1), (2867, 1), (5318, 1), (3124, 1), (2424, 1), (1762, 1), (934, 1), (7368, 1), (6392, 1), (3124, 1), (3780, 1), (6440, 1), (4638, 1), (6206, 1), (3724, 1), (5445, 1), (6158, 1), (2936, 1), (511, 1), (9155, 1), (2399, 1), (125, 1), (3299, 1), (126, 1), (3189, 1), (8024, 1), (3136, 1), (2134, 1), (818, 1), (1462, 1), (5745, 1), (2455, 1), (7563, 1), (711, 1), (1921, 1), (712, 1), (3136, 1), (1266, 1), (2123, 1), (3136, 1), (1277, 1), (712, 1), (3136, 1), (8024, 1), (1398, 1), (2399, 1), (129, 1), (3299, 1), (8115, 1), (3189, 1), (2218, 1), (818, 1), (8039, 1), (1071, 1), (4288, 1), (7208, 1), (711, 1), (519, 1), (2769, 1), (928, 1), (1921, 1), (712, 1), (4638, 1), (4263, 1), (520, 1), (511, 1), (4507, 1), (754, 1), (5745, 1), (2455, 1), (7563, 1), (6158, 1), (6632, 1), (1298, 1), (3124, 1), (2424, 1), (6763, 1), (4881, 1), (2345, 1), (679, 1), (1914, 1), (8114, 1), (2399, 1), (8024, 1), (1728, 1), (3634, 1), (800, 1), (3187, 1), (3791, 1), (1168, 1), (2792, 1), (2247, 1), (1828, 1), (1277, 1), (6822, 1), (6121, 1), (4288, 1), (4130, 1), (2339, 1), (868, 1), (5445, 1), (683, 1), (3800, 1), (4777, 1), (6438, 1), (5023, 1), (2339, 1), (868, 1), (511, 1), (5745, 1), (2455, 1), (7563, 1), (7370, 1), (749, 1), (7481, 1), (2190, 1), (2773, 1), (751, 1), (510, 1), (6577, 1), (1737, 1), (510, 1), (6158, 1), (2496, 1), (2229, 1), (6833, 1), (2154, 1), (1921, 1), (712, 1), (3136, 1), (833, 1), (5023, 1), (7309, 1), (7579, 1), (1912, 1), (8024, 1), (738, 1), (4908, 1), (2166, 1), (2612, 1), (1908, 1), (934, 1), (7368, 1), (510, 1), (1158, 1), (2456, 1), (1957, 1), (934, 1), (833, 1), (1730, 1), (860, 1), (5023, 1), (511, 1), (8431, 1), (2399, 1), (8024, 1), (3136, 1), (2134, 1), (5735, 1), (3307, 1), (924, 1), (4882, 1), (753, 1), (686, 1), (1762, 1), (1398, 1), (2399, 1), (127, 1), (3299, 1), (8123, 1), (3189, 1), (3091, 1), (1285, 1), (5745, 1), (2455, 1), (7563, 1), (711, 1), (1921, 1), (712, 1), (3136, 1), (3777, 1), (1079, 1), (2600, 1), (3136, 1), (1277, 1), (2134, 1), (2429, 1), (5392, 1), (4415, 1), (809, 1), (1856, 1), (6133, 1), (6421, 1), (3136, 1), (1277, 1), (2600, 1), (712, 1), (3136, 1), (4638, 1), (4958, 1), (5375, 1), (511, 1), (8447, 1), (2399, 1), (124, 1), (3299, 1), (8133, 1), (3189, 1), (8024, 1), (5745, 1), (2455, 1), (7563, 1), (6158, 1), (3136, 1), (2134, 1), (5735, 1), (3307, 1), (924, 1), (4882, 1), (753, 1), (686, 1), (3091, 1), (1285, 1), (711, 1), (1921, 1), (712, 1), (3136, 1), (3777, 1), (1079, 1), (2600, 1), (3136, 1), (1277, 1), (2600, 1), (712, 1), (3136, 1), (2400, 1), (1076, 1), (1921, 1), (712, 1), (3136, 1), (6446, 1), (2255, 1), (3136, 1), (1277, 1), (2134, 1), (2429, 1), (5392, 1), (4415, 1), (8039, 1), (1398, 1), (2399, 1), (8111, 1), (3299, 1), (8153, 1), (3189, 1), (8024, 1), (5735, 1), (3307, 1), (924, 1), (4882, 1), (753, 1), (686, 1), (3091, 1), (1285, 1), (5745, 1), (2455, 1), (7563, 1), (711, 1), (3364, 1), (3322, 1), (511, 1), (5745, 1), (2455, 1), (7563, 1), (1762, 1), (8396, 1), (2399, 1), (5635, 1), (8285, 1), (2399, 1), (3309, 1), (7313, 1), (1139, 1), (818, 1), (1921, 1), (712, 1), (3136, 1), (6632, 1), (1298, 1), (712, 1), (3136, 1), (1730, 1), (712, 1), (2375, 1), (511, 1), (8263, 1), (2399, 1), (125, 1), (3299, 1), (8153, 1), (3189, 1), (8024, 1), (3136, 1), (2134, 1), (5735, 1), (3307, 1), (924, 1), (4882, 1), (753, 1), (686, 1), (818, 1), (1462, 1), (1921, 1), (712, 1), (3136, 1), (6446, 1), (2255, 1), (3136, 1), (1277, 1), (1076, 1), (1921, 1), (712, 1), (3136, 1), (7770, 1), (2398, 1), (3136, 1), (1277, 1), (1426, 1), (1045, 1), (3345, 1), (712, 1), (3136, 1), (711, 1), (1921, 1), (712, 1), (3136, 1), (3777, 1), (1079, 1), (2600, 1), (3136, 1), (1277, 1), (5392, 1), (4415, 1), (712, 1), (3136, 1), (8039, 1), (1350, 1), (5635, 1), (8232, 1), (2399, 1), (123, 1), (3299, 1), (8131, 1), (3189, 1), (8024, 1), (5745, 1), (2455, 1), (7563, 1), (1728, 1), (5815, 1), (2821, 1), (6791, 1), (1343, 1), (2600, 1), (712, 1), (3136, 1), (5466, 1), (1218, 1), (5445, 1), (5783, 1), (828, 1), (8039, 1), (1426, 1), (1045, 1), (3345, 1), (1398, 1), (3189, 1), (4696, 1), (7370, 1), (1921, 1), (712, 1), (3136, 1), (3777, 1), (1079, 1), (2600, 1), (3136, 1), (1277, 1), (2600, 1), (712, 1), (3136, 1), (5466, 1), (1218, 1), (511, 1), (5745, 1), (2455, 1), (7563, 1), (754, 1), (8170, 1), (2399, 1), (123, 1), (3299, 1), (8130, 1), (3189, 1), (3926, 1), (3247, 1), (1762, 1), (3777, 1), (1079, 1), (4895, 1), (686, 1), (8024, 1), (775, 1), (2399, 1), (8426, 1), (2259, 1), (8039, 1), (1071, 1), (5873, 1), (4851, 1), (754, 1), (1398, 1), (3299, 1), (8153, 1), (3189, 1), (677, 1), (1286, 1), (1762, 1), (1921, 1), (712, 1), (3136, 1), (3777, 1), (1079, 1), (2600, 1), (3136, 1), (1277, 1), (2600, 1), (712, 1), (3136, 1), (2429, 1), (1828, 1), (715, 1), (6121, 1), (511, 1), (102, 1)]\n"
     ]
    }
   ],
   "source": [
    "# input ids 中 101是cls字段，102是sep字段，token_type_ids中0是第一个句子(问题)，1是第二个句子(字段文本)\n",
    "print(list(zip(tokenized_examp[\"input_ids\"][0], tokenized_examp[\"token_type_ids\"][0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1在tokenizer中做更精细的处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_examples = tokenizer(text=sample_dataset[\"question\"],\n",
    "                                text_pair=sample_dataset[\"context\"],\n",
    "                                return_offsets_mapping=True,\n",
    "                                max_length=512, truncation=\"only_second\", padding=\"max_length\")\n",
    "# 只对第二个进行截断，第一个(question)不截断\n",
    "tokenized_examples.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 13), (13, 14), (14, 15), (0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 13), (13, 14), (14, 15), (15, 16), (16, 17), (17, 18), (18, 19), (19, 20), (20, 21), (21, 22), (22, 23), (23, 24), (24, 25), (25, 26), (26, 27), (27, 28), (28, 29), (29, 30), (30, 34), (34, 35), (35, 36), (36, 37), (37, 38), (38, 39), (39, 40), (40, 41), (41, 45), (45, 46), (46, 47), (47, 48), (48, 49), (49, 50), (50, 51), (51, 52), (52, 53), (53, 54), (54, 55), (55, 56), (56, 57), (57, 58), (58, 59), (59, 60), (60, 61), (61, 62), (62, 63), (63, 67), (67, 68), (68, 69), (69, 70), (70, 71), (71, 72), (72, 73), (73, 74), (74, 75), (75, 76), (76, 77), (77, 78), (78, 79), (79, 80), (80, 81), (81, 82), (82, 83), (83, 84), (84, 85), (85, 86), (86, 87), (87, 91), (91, 92), (92, 93), (93, 94), (94, 95), (95, 96), (96, 97), (97, 98), (98, 99), (99, 100), (100, 101), (101, 105), (105, 106), (106, 107), (107, 108), (108, 110), (110, 111), (111, 112), (112, 113), (113, 114), (114, 115), (115, 116), (116, 117), (117, 118), (118, 119), (119, 120), (120, 121), (121, 122), (122, 123), (123, 124), (124, 125), (125, 126), (126, 127), (127, 128), (128, 129), (129, 130), (130, 131), (131, 132), (132, 133), (133, 134), (134, 135), (135, 136), (136, 137), (137, 138), (138, 139), (139, 140), (140, 141), (141, 142), (142, 143), (143, 144), (144, 145), (145, 146), (146, 147), (147, 148), (148, 149), (149, 150), (150, 151), (151, 152), (152, 153), (153, 154), (154, 155), (155, 156), (156, 157), (157, 158), (158, 159), (159, 163), (163, 164), (164, 165), (165, 166), (166, 167), (167, 168), (168, 169), (169, 170), (170, 171), (171, 172), (172, 173), (173, 174), (174, 175), (175, 176), (176, 177), (177, 178), (178, 179), (179, 180), (180, 181), (181, 182), (182, 186), (186, 187), (187, 188), (188, 189), (189, 190), (190, 191), (191, 192), (192, 193), (193, 194), (194, 195), (195, 196), (196, 197), (197, 198), (198, 199), (199, 200), (200, 201), (201, 202), (202, 203), (203, 204), (204, 205), (205, 206), (206, 207), (207, 208), (208, 209), (209, 210), (210, 211), (211, 212), (212, 213), (213, 214), (214, 215), (215, 216), (216, 217), (217, 218), (218, 222), (222, 223), (223, 224), (224, 225), (225, 226), (226, 227), (227, 228), (228, 229), (229, 230), (230, 231), (231, 232), (232, 233), (233, 234), (234, 235), (235, 236), (236, 237), (237, 238), (238, 239), (239, 240), (240, 241), (241, 242), (242, 243), (243, 244), (244, 245), (245, 246), (246, 247), (247, 248), (248, 249), (249, 250), (250, 251), (251, 252), (252, 253), (253, 257), (257, 258), (258, 259), (259, 260), (260, 261), (261, 262), (262, 263), (263, 264), (264, 265), (265, 266), (266, 267), (267, 268), (268, 269), (269, 270), (270, 271), (271, 272), (272, 273), (273, 274), (274, 275), (275, 276), (276, 277), (277, 278), (278, 279), (279, 280), (280, 281), (281, 282), (282, 283), (283, 284), (284, 285), (285, 286), (286, 287), (287, 288), (288, 289), (289, 290), (290, 291), (291, 292), (292, 293), (293, 294), (294, 295), (295, 296), (296, 297), (297, 298), (298, 299), (299, 300), (300, 301), (301, 302), (302, 303), (303, 304), (304, 305), (305, 306), (306, 307), (307, 308), (308, 309), (309, 310), (310, 311), (311, 312), (312, 313), (313, 314), (314, 315), (315, 316), (316, 317), (317, 318), (318, 319), (319, 320), (320, 321), (321, 325), (325, 326), (326, 327), (327, 328), (328, 329), (329, 330), (330, 331), (331, 332), (332, 333), (333, 334), (334, 335), (335, 336), (336, 337), (337, 338), (338, 339), (339, 340), (340, 341), (341, 342), (342, 343), (343, 344), (344, 345), (345, 346), (346, 347), (347, 348), (348, 349), (349, 350), (350, 351), (351, 352), (352, 353), (353, 354), (354, 355), (355, 356), (356, 360), (360, 361), (361, 362), (362, 363), (363, 364), (364, 365), (365, 366), (366, 367), (367, 368), (368, 369), (369, 370), (370, 371), (371, 372), (372, 373), (373, 374), (374, 375), (375, 376), (376, 377), (377, 378), (378, 379), (379, 380), (380, 381), (381, 382), (382, 383), (383, 384), (384, 385), (385, 386), (386, 387), (387, 388), (388, 390), (390, 391), (391, 392), (392, 393), (393, 394), (394, 395), (395, 396), (396, 397), (397, 398), (398, 399), (399, 400), (400, 401), (401, 402), (402, 403), (403, 404), (404, 405), (405, 406), (406, 407), (407, 408), (408, 409), (409, 410), (410, 411), (411, 412), (412, 413), (413, 414), (414, 415), (415, 416), (416, 417), (417, 418), (418, 419), (419, 420), (420, 421), (421, 422), (422, 424), (424, 425), (425, 426), (426, 427), (427, 428), (428, 429), (429, 430), (430, 431), (431, 432), (432, 433), (433, 434), (434, 435), (435, 436), (436, 437), (437, 438), (438, 439), (439, 440), (440, 441), (441, 442), (442, 443), (443, 444), (444, 445), (445, 446), (446, 447), (447, 448), (448, 449), (449, 450), (450, 451), (451, 452), (452, 453), (453, 454), (454, 455), (455, 456), (456, 457), (457, 458), (458, 459), (459, 460), (460, 461), (461, 462), (462, 463), (463, 464), (464, 465), (465, 466), (466, 467), (467, 468), (468, 469), (469, 470), (470, 471), (471, 472), (472, 473), (473, 474), (474, 475), (475, 476), (476, 477), (477, 478), (478, 479), (479, 480), (480, 481), (481, 482), (482, 483), (483, 484), (484, 485), (485, 486), (486, 487), (487, 488), (488, 489), (489, 490), (490, 491), (491, 492), (492, 493), (493, 494), (494, 495), (495, 499), (499, 500), (500, 501), (501, 502), (502, 503), (503, 504), (504, 505), (505, 506), (506, 507), (507, 508), (508, 509), (509, 510), (510, 511), (511, 512), (512, 513), (513, 514), (514, 516), (516, 517), (517, 518), (518, 519), (519, 520), (520, 521), (521, 522), (522, 523), (523, 524), (524, 525), (525, 526), (526, 527), (527, 528), (528, 529), (529, 530), (530, 531), (531, 532), (532, 533), (533, 534), (0, 0)] 512\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_examples[\"offset_mapping\"][0], len(tokenized_examples[\"offset_mapping\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_mapping = tokenized_examples.pop(\"offset_mapping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, offset in enumerate(offset_mapping):\n",
    "    answer = sample_dataset[idx][\"answers\"]\n",
    "    start_char = answer[\"answer_start\"][0]\n",
    "    end_char = start_char + len(answer[\"text\"][0])\n",
    "    # 定位答案在token中的起始位置和结束位置\n",
    "    # 一种策略，我们要拿到context的起始和结束，然后从左右两侧向答案逼近\n",
    "\n",
    "    context_start = tokenized_examples.sequence_ids(idx).index(1)\n",
    "    context_end = tokenized_examples.sequence_ids(idx).index(None, context_start) - 1\n",
    "\n",
    "    # 判断答案是否在context中\n",
    "    if offset[context_end][1] < start_char or offset[context_start][0] > end_char:\n",
    "        start_token_pos = 0\n",
    "        end_token_pos = 0\n",
    "    else:\n",
    "        token_id = context_start\n",
    "        while token_id <= context_end and offset[token_id][0] < start_char:\n",
    "            token_id += 1\n",
    "        start_token_pos = token_id\n",
    "        token_id = context_end\n",
    "        while token_id >= context_start and offset[token_id][1] > end_char:\n",
    "            token_id -=1\n",
    "        end_token_pos = token_id\n",
    "        \n",
    "    print(answer, start_char, end_char, context_start, context_end, start_token_pos, end_token_pos)\n",
    "    print(\"token answer decode:\", tokenizer.decode(tokenized_examples[\"input_ids\"][idx][start_token_pos: end_token_pos + 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_func(examples):\n",
    "    tokenized_examples = tokenizer(text=examples[\"question\"],\n",
    "                               text_pair=examples[\"context\"],\n",
    "                               return_offsets_mapping=True,\n",
    "                               max_length=384, truncation=\"only_second\", padding=\"max_length\")\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    for idx, offset in enumerate(offset_mapping):\n",
    "        answer = examples[\"answers\"][idx]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = start_char + len(answer[\"text\"][0])\n",
    "        # 定位答案在token中的起始位置和结束位置\n",
    "        # 一种策略，我们要拿到context的起始和结束，然后从左右两侧向答案逼近\n",
    "        context_start = tokenized_examples.sequence_ids(idx).index(1)\n",
    "        context_end = tokenized_examples.sequence_ids(idx).index(None, context_start) - 1\n",
    "        # 判断答案是否在context中\n",
    "        if offset[context_end][1] < start_char or offset[context_start][0] > end_char:\n",
    "            start_token_pos = 0\n",
    "            end_token_pos = 0\n",
    "        else:\n",
    "            token_id = context_start\n",
    "            while token_id <= context_end and offset[token_id][0] < start_char:\n",
    "                token_id += 1\n",
    "            start_token_pos = token_id\n",
    "            token_id = context_end\n",
    "            while token_id >= context_start and offset[token_id][1] > end_char:\n",
    "                token_id -=1\n",
    "            end_token_pos = token_id\n",
    "        start_positions.append(start_token_pos)\n",
    "        end_positions.append(end_token_pos)\n",
    "    \n",
    "    tokenized_examples[\"start_positions\"] = start_positions\n",
    "    tokenized_examples[\"end_positions\"] = end_positions\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenied_datasets = datasets.map(process_func, batched=True, remove_columns=datasets[\"train\"].column_names)\n",
    "tokenied_datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step4 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "106cac00039e4161a9a304bac33491d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/412M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hfl/chinese-macbert-base were not used when initializing BertForQuestionAnswering: ['cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at hfl/chinese-macbert-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(\"hfl/chinese-macbert-base\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step5 配置TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"models_for_qa\",\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=50,\n",
    "    num_train_epochs=3\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step6 配置Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenied_datasets[\"train\"],\n",
    "    eval_dataset=tokenied_datasets[\"validation\"],\n",
    "    data_collator=DefaultDataCollator()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step7 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step8 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"question-answering\", model=model, tokenizer=tokenizer, device=0)\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe(question=\"小明在哪里上班？\", context=\"小明在北京上班。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
